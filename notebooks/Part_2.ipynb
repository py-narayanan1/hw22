{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl as pxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file even if exported to a different folder structure will conform to its structure since the internal folder structure of input and logs is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = Path.cwd().joinpath(\"input\").joinpath(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/narayanan/Downloads/hw22_visweswaran/hw22_visweswaran/notebooks/input/logs')"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BCM type files are taken up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = BCM-E-tCenter-Deep.csv, stem = BCM-E-tCenter-Deep, suffix = .csv\n",
      "filename = BCM-E-tCenter-Medium.csv, stem = BCM-E-tCenter-Medium, suffix = .csv\n",
      "filename = BCM-E-tCenter-Shallow.csv, stem = BCM-E-tCenter-Shallow, suffix = .csv\n",
      "filename = BCM-E-tLeft-Deep.csv, stem = BCM-E-tLeft-Deep, suffix = .csv\n",
      "filename = BCM-E-tLeft-Medium.csv, stem = BCM-E-tLeft-Medium, suffix = .csv\n",
      "filename = BCM-E-tRight-Deep.csv, stem = BCM-E-tRight-Deep, suffix = .csv\n",
      "filename = BCM-E-tRight-Medium.csv, stem = BCM-E-tRight-Medium, suffix = .csv\n",
      "filename = BCM-N-tCenter-Deep.csv, stem = BCM-N-tCenter-Deep, suffix = .csv\n",
      "filename = BCM-N-tCenter-Medium.csv, stem = BCM-N-tCenter-Medium, suffix = .csv\n",
      "filename = BCM-N-tLeft-Deep.csv, stem = BCM-N-tLeft-Deep, suffix = .csv\n",
      "filename = BCM-N-tLeft-Medium.csv, stem = BCM-N-tLeft-Medium, suffix = .csv\n",
      "filename = BCM-N-tRight-Deep.csv, stem = BCM-N-tRight-Deep, suffix = .csv\n",
      "filename = BCM-N-tRight-Medium.csv, stem = BCM-N-tRight-Medium, suffix = .csv\n",
      "filename = BCM-N-tRight-Shallow.csv, stem = BCM-N-tRight-Shallow, suffix = .csv\n"
     ]
    }
   ],
   "source": [
    "for f in input_file.rglob('BCM*.csv'):\n",
    "    print(f\"filename = {f.name}, stem = {f.stem}, suffix = {f.suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an empty dictionary where the key will be the stem of the file and the value will be the datframe that has been produced off from the csv file imported for each csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rglob recursively scans through all the csv files and puts them in a format that has been mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in input_file.rglob('BCM*.csv'):\n",
    "    fstem = f.stem\n",
    "    df = pd.read_csv(f,header=None)\n",
    "    dfs[fstem] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output folder inside the notebooks folder , the BCM.xlsx file which has been manually created is accesses and then the dataframe is looped over , where in the datatypes of each column is updated and the headers are also set as per the format expected , the good thing about excelwriter is , it doesnt matter how many times we run it , if the syntax remains the same, no new excel sheets are created. in the to_excel formula , we pass in the sheet name as the key of the dictionary and which in turn is the stem name of each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('output/BCM.xlsx') as writer:\n",
    "    for sheetname,sheetdata in dfs.items():\n",
    "            sheetdata = sheetdata.astype({0: 'datetime64',1: 'string',2:'float64'})\n",
    "            sheetdata.to_excel(writer,sheet_name=sheetname,index=False,header=['datetime','scale','temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pxl is the shortform of openpyxl module which is then loaded on to the workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pxl.load_workbook(\"output/BCM.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported mean for faster processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the process of filling in each sheet created in the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"loop through all the sheetnames in the target excel file\"\"\"  \n",
    "for x in wb.sheetnames:\n",
    "    \"\"\"  Acces the worksheet with that particular sheetname\"\"\"  \n",
    "    ws = wb[x]\n",
    "    \"\"\" Fill in all the cells as have been asked for in the document since everyone of them has a common format , \n",
    "    it can be repeated\"\"\"  \n",
    "    ws['G2'] = \"min_temp\"\n",
    "    ws['G3'] = \"max_temp\"\n",
    "    ws['G4'] = \"mean_temp\"\n",
    "    ws['G6'] = \"min_date\"\n",
    "    ws['G7'] = \"max_date\"\n",
    "    \"\"\"  date cells are the cells which have been created to access just the dates\"\"\"  \n",
    "    date_cells = []\n",
    "    \"\"\"  similarily for temperature cells\"\"\"  \n",
    "    temperature_cells = []\n",
    "    \"\"\"  the row pack is a packer that creates an iterable over the rows from the 2nd to max length of the rows and it moves along\n",
    "    the first column for the dates\"\"\"  \n",
    "    for row_pack in ws['A2':'A'+str(ws.max_row)]:\n",
    "        \"\"\"  loops through the iterable \"\"\"  \n",
    "        for row in row_pack:\n",
    "            date_cells.append(row.value)\n",
    "    \"\"\"  Finds the minimum of all the dates\"\"\"  \n",
    "    ws['H6'] = min(date_cells)\n",
    "    \"\"\"  Finds the maximum of all the dates\"\"\"  \n",
    "    ws['H7'] = max(date_cells)\n",
    "    \"\"\"  Similar method for the temperature values\"\"\"  \n",
    "    for row_pack in ws['C2':'C'+str(ws.max_row)]:\n",
    "        for row in row_pack:\n",
    "            temperature_cells.append(row.value)\n",
    "    ws['H2'] = min(temperature_cells)\n",
    "    ws['H3'] = max(temperature_cells)\n",
    "    ws['H4'] = mean(temperature_cells)\n",
    "\"\"\"  Finally we save the entire updated excel file with all its changes\"\"\"  \n",
    "wb.save('output/BCM.xlsx')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since we have a different approach for it , now I have created 2 folders called logs_hacker in the input folder inside the notebooks folder , where the file names of the excel csvs have been changed to a different filename , so that for each filename and different output excel file is created which goes into a folder named output_hacker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   A set of files is created to avoid any repetition\"\"\"  \n",
    "set_of_files = set()\n",
    "dire = Path('input/logs_hacker')\n",
    "\"\"\"  A new dictionary is created for creating a stem for each new type of file name\"\"\"  \n",
    "dfs_hacker = {}\n",
    "for f in dire.glob('*.csv'):\n",
    "    fstem = f.stem\n",
    "    df_hacker = pd.read_csv(f,header=None)\n",
    "    dfs_hacker[fstem] = df_hacker\n",
    "    \"\"\"  We just access the first three letters the file to see if it is differnt\"\"\"  \n",
    "    set_of_files.add(fstem[0:fstem.index('-')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  looping through the set\"\"\"  \n",
    "for x in list(set_of_files):\n",
    "    \"\"\"  creating a workbook for each new filename\"\"\"  \n",
    "    wb = pxl.Workbook()\n",
    "    \"\"\"  saving creates the file in the destination folder.\"\"\"  \n",
    "    wb.save('output_hacker/'+x+'.xlsx')\n",
    "    \"\"\"  creating a writer object to fill in the individual excel files with their excel sheets\"\"\"  \n",
    "    with pd.ExcelWriter('output_hacker/'+x+'.xlsx') as writers:\n",
    "      for sheetname,sheetdata in dfs_hacker.items():\n",
    "        \"\"\"  checks if the sheetname is same as the filename of the new excel file created. i.e. the first three letters,if\n",
    "            yes , then creates a new sheet in that designated excel file for that kind of file and repeats the same.\"\"\"  \n",
    "        if sheetname[0:sheetname.index('-')] == x:\n",
    "            sheetdata = sheetdata.astype({0: 'datetime64',1: 'string',2:'float64'})\n",
    "            sheetdata.to_excel(writers,sheet_name=sheetname,index=False,header=['datetime','scale','temperature'])\n",
    "        else:\n",
    "            continue\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
